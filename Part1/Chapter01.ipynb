{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2bf191e9",
      "metadata": {
        "id": "2bf191e9"
      },
      "source": [
        "# Part1 빅데이터와 스파크 간단히 살펴보기\n",
        "## 1장 아파치 스파크란"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0106ef",
      "metadata": {
        "id": "bf0106ef"
      },
      "source": [
        "아파치 스파크는 클러스터 환경에서 데이터를 처리하는 라이브러리로, 네가지 언어(파이썬, 자바, 스칼라, R)를 지원하며 SQL뿐만 아니라 스트리밍, 머신러닝에 이르기까지 넓은 범위의 라이브러리를 제공한다.\n",
        "\n",
        "실제로, 단일 노트북 환경에서부터 수천 대의 서버로 구성된 클러스터까지 다양한 환경을 시작할 수 있다.\n",
        "\n",
        "![%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202023-04-14%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%206.53.52.png](attachment:%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202023-04-14%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%206.53.52.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a341de",
      "metadata": {
        "id": "e9a341de"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54396d81",
      "metadata": {
        "id": "54396d81"
      },
      "source": [
        "### 1.1 아파치 스파크의 철학\n",
        "\n",
        "**통합**\n",
        "\n",
        "스파크는 간단한 데이터 읽기 ~ SQL처리, 머신러닝 그리고 스트림 처리까지 다양한 데이터 분석 작업을 같은 연산 엔진과 일관성 있는 API로 수행할 수 있도록 설계되어있다.\n",
        "\n",
        "예를 들면, SQL쿼리로 데이터 읽기 -> ML 라이브러리로 머신러닝 모델 평가의 경우 스파크 엔진은 이 두 단계를 하나로 병합하고 데이터를 한 번만 조회할 수 있게 한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**컴퓨팅 엔진**\n",
        "\n",
        "스파크는 저장소 시스템의 데이터를 연산하는 역할만 수행할 뿐 영구 저장소 역할은 수행하지 않으므로 Azure Storage, Amazon S3, Apache Kafka등의 저장소 지원한다.\n",
        "\n",
        "이러한 구조의 이유는 데이터 이동은 높은 비용을 유발하므로 이슈로 인해서 스파크는 데이터를 오랜 시간 저장하지 않으며 특정 저장소 시스템을 선호하지 않는다.\n",
        "\n",
        "고로, 데이터 저장 위치에 상관없이 처리에 집중하도록 만들어져 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**라이브러리**\n",
        "\n",
        "스파크 컴포넌트는 데이터 분석 작업에 필요한 통합 API를 제공하는 통합 엔진 기반의 자체 라이브러리이면서 엔진에서 제공하는 표준 라이브러리와 오픈소스 커뮤니티에서 서드파티 패키지 형태로 제공하는 다양한 외부 라이브러리 지원한다.\n",
        "\n",
        "외부 라이브러리 목록은 https://spark-packages.org/ 확인하면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e80372c7",
      "metadata": {
        "id": "e80372c7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0ae47b5",
      "metadata": {
        "id": "a0ae47b5"
      },
      "source": [
        "### 1.2 스파크의 등장 배경\n",
        "\n",
        "하드웨어의 성장으로 데이터 수집 비용은 저렴해졌지만 클러스터에서 처리하는 양은 거대해졌습니다.\n",
        "\n",
        "기존의 소프트웨어로는 처리가 불가능에 가까워졌기에 새로운 프로그래밍 모델이 필요했고 이 문제를 해결하기 위해서 아파치 스파크가 탄생했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a46eceb2",
      "metadata": {
        "id": "a46eceb2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf81204d",
      "metadata": {
        "id": "bf81204d"
      },
      "source": [
        "### 1.3 스파크의 역사\n",
        "\n",
        "대상: UC 버클리 대학교의 하둡 사용자들  연구\n",
        "\n",
        "결론\n",
        "\n",
        "1. 클러스터 컴퓨팅이 엄청난 잠재력을 갖고 있다.\n",
        "2. 맵리듀스 엔진을 사용하는 대규모 애플리케이션의 난이도와 효율성 문제\n",
        "\n",
        "<br>\n",
        "\n",
        "해결\n",
        "\n",
        "- 여러 단계로 이뤄진 애플리케이션을 간결하게 개발할 수 잇는 함수형 프로그래밍 기반의 API 설계\n",
        "\n",
        "- 연산 단계 사이에서 메모리에 저장된 데이터를 효율적으로 공유할 수 있는 새로운 엔진 기반의 API 구현\n",
        "\n",
        "- 발전 단계\n",
        "\n",
        "   - 함수형 연산\n",
        "   \n",
        "   - 구조화된 데이터를 기반\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6754501",
      "metadata": {
        "id": "d6754501"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89e01458",
      "metadata": {
        "id": "89e01458"
      },
      "source": [
        "### 1.4 스파크의 현재와 미래\n",
        "\n",
        ">빅데이터 분석 수행을 위해서 필요하고 DS, DE는 스파크 공부해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3502bfad",
      "metadata": {
        "id": "3502bfad"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d646eae",
      "metadata": {
        "id": "7d646eae"
      },
      "source": [
        "### 1.5 스파크 실행하기\n",
        "\n",
        "**1.5.1로컬 환경에 스파크 내려받기**\n",
        "\n",
        "로컬 환경에서 스파크를 내려받아 실행하려면 자바가 설치되어야 한다.(명령행에 java를 입력해 확인)\n",
        "\n",
        "파이썬으로 스파크를 사용하려면 설치된 파이썬 버전 확인\n",
        "\n",
        "스파크 프로젝트의 공식 홈페이지에 접속해 패키지 유형을 'pre-bulit for Hadoop 2.7 and later'로 선택하고 Direct Download클릭\n",
        "\n",
        "내려받은 타르볼 파일의 압축\n",
        "\n",
        "스파크 버전 2.2이상\n",
        "\n",
        "<br>\n",
        "\n",
        "**소스에서 직접 빌드**\n",
        "\n",
        "아파치 다운로드 페이지에서 소스 패키지를 선택한 후 내려받고 README 파일의 내용에 따라 빌드\n",
        "\n",
        "스파크를 내려받고 명령행에서 내려받은 파일의 압축을 푼 후 디렉터리로 이동하는 코드 스닛펫이며 모든 Unix 형태의 명령행에서 실행\n",
        "\n",
        "cd ~/Downloads\n",
        "\n",
        "tar -xf spark-2.2.0-bin-hadoop2.7.tgz\n",
        "\n",
        "cd spark-2.2.0-bin-hadoop2.7.tgz\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**1.5.2 스파크 대화형 콘솔 실행하기**\n",
        "\n",
        "파이썬 콘솔 실행하기: ./bin/pyspark\n",
        "\n",
        "스칼라 콘솔 실행하기: ./bin/spark-shell\n",
        "\n",
        "SQL 콘솔 실행하기: ./bin/spark-sql\n",
        "\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518c8705",
      "metadata": {
        "id": "518c8705"
      },
      "source": [
        "\n",
        "- 스파크 학습용 무료 클라우드 환경인 웹 기반 데이터브릭스 커뮤니티 버전 실행\n",
        "\n",
        "https://sparkdia.tistory.com/61\n",
        "\n",
        "- 도커 환경: 부록 A"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}